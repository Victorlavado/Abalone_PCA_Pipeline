{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ABALONE YEARS PREDICTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abalone is the common name in the US for *Haliotis*, other terms are Paua (NZ) or Omer (UK). They all refer to a type molluscs with big shells <br>\n",
    "The aim of this notebook is to predict the age of abalone from physical measurements, by working in different scenarios. The age (in years) is obtained by adding 1.5 to the number of rings (last column of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Atribute selection with PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Libraries import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import decomposition\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Abalone = pd.read_csv(\"abalone.csv\", sep=\",\", decimal=\".\")\n",
    "X = Abalone.iloc[:,:-1]\n",
    "y = Abalone.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole weight</th>\n",
       "      <th>Shucked weight</th>\n",
       "      <th>Viscera weight</th>\n",
       "      <th>Shell weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>M</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>I</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.055</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sex   Length   Diameter   Height   Whole weight   Shucked weight  \\\n",
       "0   M    0.455      0.365    0.095         0.5140           0.2245   \n",
       "1   M    0.350      0.265    0.090         0.2255           0.0995   \n",
       "2   F    0.530      0.420    0.135         0.6770           0.2565   \n",
       "3   M    0.440      0.365    0.125         0.5160           0.2155   \n",
       "4   I    0.330      0.255    0.080         0.2050           0.0895   \n",
       "\n",
       "    Viscera weight   Shell weight  \n",
       "0           0.1010          0.150  \n",
       "1           0.0485          0.070  \n",
       "2           0.1415          0.210  \n",
       "3           0.1140          0.155  \n",
       "4           0.0395          0.055  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    15\n",
       "1     7\n",
       "2     9\n",
       "3    10\n",
       "4     7\n",
       "Name:  Rings, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Sex']\n"
     ]
    }
   ],
   "source": [
    "# Get list of categorical attributes\n",
    "\n",
    "s = (X.dtypes == 'object')\n",
    "object_cols = list(s[s].index)\n",
    "print(object_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Turn the categorical attribute into several numerical attributes, to be able to process the data with Scikit Learn models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "Encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "Encoder_train = pd.DataFrame(Encoder.fit_transform(X_train[object_cols]))\n",
    "Encoder_test = pd.DataFrame(Encoder.fit_transform(X_test[object_cols]))\n",
    "\n",
    "# Put back the index\n",
    "Encoder_train.index = X_train.index\n",
    "Encoder_test.index = X_test.index\n",
    "\n",
    "# Remove original categorical attributes\n",
    "num_X_train = X_train.drop(object_cols, axis=1)\n",
    "num_X_test = X_test.drop(object_cols, axis=1)\n",
    "\n",
    "# Add the one-hot encoded columns\n",
    "Encoded_X_train = pd.concat([num_X_train, Encoder_train], axis=1)\n",
    "Encoded_X_test = pd.concat([num_X_test, Encoder_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole weight</th>\n",
       "      <th>Shucked weight</th>\n",
       "      <th>Viscera weight</th>\n",
       "      <th>Shell weight</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2248</td>\n",
       "      <td>0.360</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2225</td>\n",
       "      <td>0.0830</td>\n",
       "      <td>0.0530</td>\n",
       "      <td>0.0750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1966</td>\n",
       "      <td>0.665</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.150</td>\n",
       "      <td>1.2475</td>\n",
       "      <td>0.4625</td>\n",
       "      <td>0.2955</td>\n",
       "      <td>0.3595</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2760</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.7120</td>\n",
       "      <td>0.3025</td>\n",
       "      <td>0.1520</td>\n",
       "      <td>0.2250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.355</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.2455</td>\n",
       "      <td>0.0955</td>\n",
       "      <td>0.0620</td>\n",
       "      <td>0.0750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>838</td>\n",
       "      <td>0.480</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6395</td>\n",
       "      <td>0.2945</td>\n",
       "      <td>0.1130</td>\n",
       "      <td>0.1750</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Length   Diameter   Height   Whole weight   Shucked weight  \\\n",
       "2248    0.360      0.270    0.090         0.2225           0.0830   \n",
       "1966    0.665      0.500    0.150         1.2475           0.4625   \n",
       "2760    0.550      0.430    0.145         0.7120           0.3025   \n",
       "20      0.355      0.280    0.095         0.2455           0.0955   \n",
       "838     0.480      0.365    0.135         0.6395           0.2945   \n",
       "\n",
       "       Viscera weight   Shell weight    0    1    2  \n",
       "2248           0.0530         0.0750  0.0  0.0  1.0  \n",
       "1966           0.2955         0.3595  1.0  0.0  0.0  \n",
       "2760           0.1520         0.2250  0.0  1.0  0.0  \n",
       "20             0.0620         0.0750  0.0  0.0  1.0  \n",
       "838            0.1130         0.1750  1.0  0.0  0.0  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Encoded_X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole weight</th>\n",
       "      <th>Shucked weight</th>\n",
       "      <th>Viscera weight</th>\n",
       "      <th>Shell weight</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2806</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.170</td>\n",
       "      <td>1.7110</td>\n",
       "      <td>0.8365</td>\n",
       "      <td>0.3520</td>\n",
       "      <td>0.4750</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2251</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.175</td>\n",
       "      <td>1.2675</td>\n",
       "      <td>0.4995</td>\n",
       "      <td>0.2815</td>\n",
       "      <td>0.3800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3771</td>\n",
       "      <td>0.575</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.7950</td>\n",
       "      <td>0.3640</td>\n",
       "      <td>0.1505</td>\n",
       "      <td>0.2600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3819</td>\n",
       "      <td>0.570</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.9275</td>\n",
       "      <td>0.4770</td>\n",
       "      <td>0.1605</td>\n",
       "      <td>0.2515</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1690</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.170</td>\n",
       "      <td>1.0985</td>\n",
       "      <td>0.4645</td>\n",
       "      <td>0.2200</td>\n",
       "      <td>0.3540</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Length   Diameter   Height   Whole weight   Shucked weight  \\\n",
       "2806    0.675      0.525    0.170         1.7110           0.8365   \n",
       "2251    0.600      0.485    0.175         1.2675           0.4995   \n",
       "3771    0.575      0.450    0.145         0.7950           0.3640   \n",
       "3819    0.570      0.450    0.140         0.9275           0.4770   \n",
       "1690    0.625      0.500    0.170         1.0985           0.4645   \n",
       "\n",
       "       Viscera weight   Shell weight    0    1    2  \n",
       "2806           0.3520         0.4750  1.0  0.0  0.0  \n",
       "2251           0.2815         0.3800  0.0  0.0  1.0  \n",
       "3771           0.1505         0.2600  0.0  1.0  0.0  \n",
       "3819           0.1605         0.2515  0.0  0.0  1.0  \n",
       "1690           0.2200         0.3540  0.0  0.0  1.0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Encoded_X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because PCA is affected by standarization, it is necessary to scale the attributes before applying PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "# First fit the training set only\n",
    "\n",
    "scaler.fit(Encoded_X_train)\n",
    "\n",
    "# Then apply transform to train and test sets\n",
    "\n",
    "Encoded_X_train = scaler.transform(Encoded_X_train)\n",
    "Encoded_X_test = scaler.transform(Encoded_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2923, 10)\n"
     ]
    }
   ],
   "source": [
    "print(Encoded_X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the maximum number of PCA components for the moment(which implies 10 PCA components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=10, random_state=None,\n",
       "    svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_init = decomposition.PCA(n_components=10)\n",
    "pca_init.fit(Encoded_X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let´s see how much variance explains each of the ten components. It´s clear to see that just the four first components alone explain more than 90%. This is because PCA procedure orders the components from the most important to the least important "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.90244196e-01, 1.51438414e-01, 9.11817285e-02, 3.07036500e-02,\n",
       "       1.65957041e-02, 1.14532385e-02, 6.57433451e-03, 1.13919709e-03,\n",
       "       6.69537055e-04, 8.71620317e-33])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca_init.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be seen graphycally as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = np.array([0])\n",
    "concat = np.concatenate((a, pca_init.explained_variance_ratio_), axis=0)\n",
    "accumulated_variance = np.cumsum(concat)\n",
    "plt.plot(accumulated_variance)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, let's compute just 4 PCA components and apply them to train and test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_init = decomposition.PCA(n_components=4)\n",
    "pca_init.fit(Encoded_X_train)\n",
    "X_train_red = pca_init.transform(Encoded_X_train)\n",
    "X_test_red = pca_init.transform(Encoded_X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can apply a regression tree model to the new, reduced, training set, and test it on the transformed test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeRegressor(random_state=0)\n",
    "clf = clf.fit(X_train_red, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for the training set using 3 pca is 0.0\n",
      "MAE for the test set using 3 pca is 2.3309409888357258\n"
     ]
    }
   ],
   "source": [
    "y_train_pred = clf.predict(X_train_red)\n",
    "y_pred = clf.predict(X_test_red)\n",
    "print (\"MAE for the training set using 3 pca is {}\".format(mean_absolute_error(y_train, y_train_pred)))\n",
    "print (\"MAE for the test set using 3 pca is {}\".format(mean_absolute_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to reduce the dimesion of the problem from 10 to 4, however, while obtaining a MAE of 2.3 approximately. Do not forget that we are predicting  the age of the abalone (rings on the shell plus 1.5), so the unit of MAE is years"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let´s see what would happen if we use all the original attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for the training set using all the attributes is 0.0\n",
      "Accuracy for the test set using all the attributes is 2.148325358851675\n"
     ]
    }
   ],
   "source": [
    "clf = tree.DecisionTreeRegressor(random_state=0)\n",
    "clf = clf.fit(Encoded_X_train, y_train)\n",
    "y_train_pred = clf.predict(Encoded_X_train)\n",
    "y_pred = clf.predict(Encoded_X_test)\n",
    "print (\"Accuracy for the training set using all the attributes is {}\".format(mean_absolute_error(y_train, y_train_pred)))\n",
    "print (\"Accuracy for the test set using all the attributes is {}\".format(mean_absolute_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAE is pretty similar using 6 more attributes, which means that attribute selection with PCA works reasonably well (with a tree regressor). In practical terms, the years of abalones are predicted just with 3 attributes, which means that in the case of large dataset (big data approach), the number of values will be reduced in a 60%, thus optimizing the process substantially."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As, the attribute reduction seems to work pretty well, let´s try it now with a different model. A Random Forest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for the training set using 3 pca is 0.698323640095792\n",
      "Accuracy for the test set using 3 pca is 1.9051834130781502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "clf = RandomForestRegressor(random_state=0)\n",
    "clf = clf.fit(X_train_red, y_train)\n",
    "y_train_pred = clf.predict(X_train_red)\n",
    "y_pred = clf.predict(X_test_red)\n",
    "print (\"Accuracy for the training set using 3 pca is {}\".format(mean_absolute_error(y_train, y_train_pred)))\n",
    "print (\"Accuracy for the test set using 3 pca is {}\".format(mean_absolute_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The increase in test accuracy using 4 components in a regressor tree versus random forest it is not very significative (2.33 vs 1.90 years). However the training accuracy has decreased (0 vs 0.69 years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for the training set using 3 pca is 0.6207321245295928\n",
      "Accuracy for the test set using 3 pca is 1.6453748006379587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestRegressor(random_state=0)\n",
    "clf = clf.fit(Encoded_X_train, y_train)\n",
    "y_train_pred = clf.predict(Encoded_X_train)\n",
    "y_pred = clf.predict(Encoded_X_test)\n",
    "print (\"Accuracy for the training set using 3 pca is {}\".format(mean_absolute_error(y_train, y_train_pred)))\n",
    "print (\"Accuracy for the test set using 3 pca is {}\".format(mean_absolute_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, when using all the attributes, the changes in test accuracy is slightly more relevant if regressor tree is compared with a random forest (2.14 vs 1.64 years)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tunning the number of PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of PCA components can also be considered as a hyper-parameter, and it is possible to use a pipeline in order to select the right number of components. Let´s use that approach, so results can be analyzed later on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    1.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('attribute_selection',\n",
       "                                        PCA(copy=True, iterated_power='auto',\n",
       "                                            n_components=None,\n",
       "                                            random_state=None,\n",
       "                                            svd_solver='auto', tol=0.0,\n",
       "                                            whiten=False)),\n",
       "                                       ('tree',\n",
       "                                        DecisionTreeRegressor(criterion='mse',\n",
       "                                                              max_depth=None,\n",
       "                                                              max_features=None,\n",
       "                                                              max_leaf_nodes=None,\n",
       "                                                              min_impurity_decrease=0.0,\n",
       "                                                              min_impurity_split=None,\n",
       "                                                              min_samples_leaf=1,\n",
       "                                                              min_samples_split=2,\n",
       "                                                              min_weight_fraction_leaf=0.0,\n",
       "                                                              presort=False,\n",
       "                                                              random_state=0,\n",
       "                                                              splitter='best'))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=1,\n",
       "             param_grid={'attribute_selection__n_components': range(1, 11)},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='neg_mean_absolute_error', verbose=1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = decomposition.PCA()\n",
    "\n",
    "# Define the paramter grid with the number of components\n",
    "# to be used by PCA from 1 to 10\n",
    "param_grid = {'attribute_selection__n_components': range(1,11)}\n",
    "\n",
    "clf = Pipeline([\n",
    "    ('attribute_selection', pca),\n",
    "    ('tree', tree.DecisionTreeRegressor(random_state=0))\n",
    "])\n",
    "\n",
    "optPcaTree = GridSearchCV(clf, \n",
    "                              param_grid, \n",
    "                              cv=5,\n",
    "                              n_jobs=1,\n",
    "                              verbose=1,\n",
    "                              scoring='neg_mean_absolute_error')\n",
    "\n",
    "# Fit is done with the complete training set \n",
    "\n",
    "optPcaTree.fit(Encoded_X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'attribute_selection__n_components': 10} 2.041737940472118\n"
     ]
    }
   ],
   "source": [
    "print (optPcaTree.best_params_, -optPcaTree.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimal number of PCA components for the tree model is equal to 10 (the maximum possible value). So the hyper-parameter tunning of PCA, results on larger number of attributes than \"selecting\" manually the minimum number of attributes with maximum variance explained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Done  50 out of  50 | elapsed:    4.3s finished\n",
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('attribute_selection',\n",
       "                                        PCA(copy=True, iterated_power='auto',\n",
       "                                            n_components=None,\n",
       "                                            random_state=None,\n",
       "                                            svd_solver='auto', tol=0.0,\n",
       "                                            whiten=False)),\n",
       "                                       ('forest',\n",
       "                                        RandomForestRegressor(bootstrap=True,\n",
       "                                                              criterion='mse',\n",
       "                                                              max_depth=None,\n",
       "                                                              max_features='auto',\n",
       "                                                              max_leaf_nodes=None,\n",
       "                                                              min_impu...\n",
       "                                                              min_samples_leaf=1,\n",
       "                                                              min_samples_split=2,\n",
       "                                                              min_weight_fraction_leaf=0.0,\n",
       "                                                              n_estimators='warn',\n",
       "                                                              n_jobs=None,\n",
       "                                                              oob_score=False,\n",
       "                                                              random_state=0,\n",
       "                                                              verbose=0,\n",
       "                                                              warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=1,\n",
       "             param_grid={'attribute_selection__n_components': range(1, 11)},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='neg_mean_absolute_error', verbose=1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = decomposition.PCA()\n",
    "\n",
    "# Define the paramter grid with the number of components\n",
    "# to be used by PCA from 1 to 10\n",
    "param_grid = {'attribute_selection__n_components': range(1,11)}\n",
    "\n",
    "clf = Pipeline([\n",
    "    ('attribute_selection', pca),\n",
    "    ('forest', RandomForestRegressor(random_state=0))\n",
    "])\n",
    "\n",
    "optPcaForest = GridSearchCV(clf, \n",
    "                              param_grid, \n",
    "                              cv=5,\n",
    "                              n_jobs=1,\n",
    "                              verbose=1,\n",
    "                              scoring='neg_mean_absolute_error')\n",
    "\n",
    "# Fit is done with the complete training set \n",
    "\n",
    "optPcaForest.fit(Encoded_X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'attribute_selection__n_components': 9} 1.5432774546698598\n"
     ]
    }
   ],
   "source": [
    "print (optPcaForest.best_params_, -optPcaForest.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scenario is analogous to the previous one with a tree regressor, but in this ocassion the number of dimensions is equal to 9, however the prediction of how many years is the most accurate one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|**Model**|**Tunning of PCA**|**Number of components**|**Test MAE**|\n",
    "|---------|------------------|------------------------|-------|\n",
    "|Tree Regressor|No|3|2.33|\n",
    "|Random Forest Regressor|No|3|1.90|\n",
    "|Tree Regressor|Yes|10|2.04|\n",
    "|Random Forest Regressor|Yes|9|1.54|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
